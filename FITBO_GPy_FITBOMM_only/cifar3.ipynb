{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "BCwdp9QGStEv",
        "colab_type": "code",
        "outputId": "506a9b0b-c6fc-493b-9885-2cd133c5384a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://jamjs98764:\"Jamjs987^$\"@github.com/jamjs98764/4yp-bo.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '4yp-bo'...\n",
            "remote: Enumerating objects: 2552, done.\u001b[K\n",
            "remote: Counting objects: 100% (2552/2552), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2393/2393), done.\u001b[K\n",
            "remote: Total 16340 (delta 261), reused 2421 (delta 139), pack-reused 13788\u001b[K\n",
            "Receiving objects: 100% (16340/16340), 106.08 MiB | 22.39 MiB/s, done.\n",
            "Resolving deltas: 100% (4150/4150), done.\n",
            "Checking out files: 100% (9049/9049), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IGkjSXRTWKil",
        "colab_type": "code",
        "outputId": "1727e16c-88be-4bdf-be9e-8d2eba634cf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install GPy\n",
        "!pip install sobol_seq"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: GPy in /usr/local/lib/python3.6/dist-packages (1.9.6)\n",
            "Requirement already satisfied: paramz>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from GPy) (0.9.4)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.6/dist-packages (from GPy) (1.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from GPy) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from GPy) (1.16.3)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.6/dist-packages (from paramz>=0.9.0->GPy) (4.4.0)\n",
            "Collecting sobol_seq\n",
            "  Downloading https://files.pythonhosted.org/packages/89/7a/7b374fd1f100bfea2624190f3dd879029e1aabe70d34e279ef456d522717/sobol_seq-0.1.2.zip\n",
            "Building wheels for collected packages: sobol-seq\n",
            "  Building wheel for sobol-seq (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d5/72/1f/6cd8a0b472da802ee9c84fdc39626bb4ec544668c030917d9f\n",
            "Successfully built sobol-seq\n",
            "Installing collected packages: sobol-seq\n",
            "Successfully installed sobol-seq-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RU-eleCUThBu",
        "colab_type": "code",
        "outputId": "48e2e208-f233-4710-ce49-3e8998a3c522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow import set_random_seed\n",
        "import cifar_utils\n",
        "\n",
        "from class_FITBOMM import Bayes_opt\n",
        "from class_FITBOMM import Bayes_opt_batch\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 20s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qvrOCvU5UUAF",
        "colab_type": "code",
        "outputId": "bcf065ea-7a20-4582-bbdb-3f16f64904ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "cell_type": "code",
      "source": [
        "seed_size = 1\n",
        "total_evals = 48\n",
        "\n",
        "# For FITBO\n",
        "num_continuous_dim = 4\n",
        "num_discrete_dim = 2\n",
        "num_categorical_dim = 0\n",
        "\n",
        "input_dim = num_continuous_dim + num_discrete_dim + num_categorical_dim\n",
        "input_type = [True, True, False, False, False, False] # True if domain is discrete\n",
        "\n",
        "\"\"\"\n",
        "batch_size = x[0]\n",
        "fc_units = x[1]\n",
        "l1_dropout = x[2]\n",
        "l2_dropout = x[3]\n",
        "l3_dropout = x[4]\n",
        "rms_l_rate = x[5]\n",
        "\"\"\"\n",
        "\n",
        "discrete_bounds = [(4,256), (32, 1024)]\n",
        "fitbo_lb = [discrete_bounds[0][0], discrete_bounds[1][0]]\n",
        "fitbo_ub = [discrete_bounds[0][1], discrete_bounds[1][0]]\n",
        "continuous_bounds = [(0.0,1.0),\n",
        "                     (0.0,1.0),\n",
        "                     (0.0,1.0),\n",
        "                     (0.00001, 0.1),]\n",
        "for i in continuous_bounds:\n",
        "    fitbo_lb.append(i[0])\n",
        "    fitbo_ub.append(i[1])\n",
        "\n",
        "categorical_choice = []\n",
        "\n",
        "params_simple = {\"batch_size\": 32,\n",
        "                 \"fc_units\": 512,\n",
        "          \"l1_dropout\": 0.25,\n",
        "          \"l2_dropout\": 0.25,\n",
        "          \"l3_dropout\": 0.5,\n",
        "          \"rms_l_rate\": 0.0001,\n",
        "          }\n",
        "\n",
        "#####\n",
        "# Initial Points\n",
        "#####\n",
        "np.random.seed(1)\n",
        "set_random_seed(1)\n",
        "initial_num = 3\n",
        "x_ob1 = np.array([16, 256, 0.2, 0.3, 0.2, 0.001])\n",
        "x_ob2 = np.array([64, 128,  0.5, 0.5, 0.5, 0.0001])\n",
        "x_ob3 = np.array([64, 512, 0.0, 0.0, 0.0, 0.01])\n",
        "\n",
        "x_ob = np.vstack((x_ob1, x_ob2, x_ob3))\n",
        "\n",
        "y_ob = cifar_utils.cifar_cnn_fitbo(x_ob)\n",
        "print(y_ob)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 17s 341us/step - loss: 1.4376 - acc: 0.4903 - val_loss: 1.1232 - val_acc: 0.6023\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 18s 359us/step - loss: 1.1934 - acc: 0.5943 - val_loss: 1.1479 - val_acc: 0.6121\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 16s 319us/step - loss: 1.1945 - acc: 0.6046 - val_loss: 0.9857 - val_acc: 0.6672\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 16s 319us/step - loss: 1.2535 - acc: 0.5885 - val_loss: 1.0662 - val_acc: 0.6467\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 16s 319us/step - loss: 1.3107 - acc: 0.5759 - val_loss: 1.2990 - val_acc: 0.5755\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 7s 148us/step - loss: 2.0757 - acc: 0.2281 - val_loss: 1.8009 - val_acc: 0.3817\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 7s 130us/step - loss: 1.7699 - acc: 0.3526 - val_loss: 1.5803 - val_acc: 0.4343\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 7s 136us/step - loss: 1.6274 - acc: 0.4030 - val_loss: 1.4612 - val_acc: 0.4842\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 7s 138us/step - loss: 1.5435 - acc: 0.4386 - val_loss: 1.3970 - val_acc: 0.4927\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 1.4787 - acc: 0.4631 - val_loss: 1.3350 - val_acc: 0.5306\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 7s 150us/step - loss: 14.4899 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "[[-0.5755]\n",
            " [-0.5306]\n",
            " [-0.1   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1HkkzJkQoeYw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.save(\"y_ob.npy\", y_ob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ivJUVWPbUUCj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cifar_fitbo_wrapper(batch_size, heuristic = \"cl-min\"):\n",
        "\n",
        "    BO_method = 'FITBOMM'\n",
        "    burnin = 100\n",
        "    sample_size = 50\n",
        "    resample_interval = 1\n",
        "\n",
        "    save_dir = os.path.join(os.getcwd(), 'Exp_Data/cifar10')\n",
        "    dir_name = save_dir + \"/FITBO/\" + str(batch_size) + \"_batch\"\n",
        "\n",
        "    if batch_size == 1: # Sequential\n",
        "        heuristic = \"sequential\"\n",
        "        results_X_hist = np.zeros(shape=(seed_size, total_evals + initial_num, input_dim))\n",
        "        results_X_optimum = np.zeros(shape=(seed_size, total_evals + 1, input_dim))\n",
        "        results_Y_hist = np.zeros(shape=(seed_size, total_evals + initial_num))\n",
        "        results_Y_optimum = np.zeros(shape=(seed_size, total_evals + 1))\n",
        "\n",
        "        for seed in range(seed_size):\n",
        "            np.random.seed(seed)\n",
        "            set_random_seed(seed)\n",
        "            print(\"Currently on seed: \", seed)\n",
        "\n",
        "            bayes_opt = Bayes_opt(cifar_utils.cifar_cnn_fitbo, fitbo_lb, fitbo_ub, var_noise = 0, input_type = input_type)\n",
        "            bayes_opt.initialise(x_ob, y_ob)\n",
        "            X_optimum, Y_optimum = bayes_opt.iteration_step(iterations=total_evals, mc_burn=burnin, \\\n",
        "                                                            mc_samples=sample_size, bo_method=BO_method, \\\n",
        "                                                            seed=seed, resample_interval= resample_interval, \\\n",
        "                                                            dir_name = dir_name)\n",
        "            results_X_hist[seed, :] = bayes_opt.X\n",
        "            results_X_optimum[seed, :] = X_optimum\n",
        "            results_Y_hist[seed, :] = bayes_opt.Y.flatten()\n",
        "            results_Y_optimum[seed, :] = Y_optimum.flatten()\n",
        "\n",
        "\n",
        "            X_file_name = dir_name + \"batch_\" + str(batch_size) + \",seed_\" + str(seed_size) + \",\" + str(heuristic) + \",X_optimum\"\n",
        "            Y_file_name = dir_name + \"batch_\" + str(batch_size) + \",seed_\" + str(seed_size) + \",\" + str(heuristic) + \",Y_optimum\"\n",
        "            X_hist_file_name = dir_name + \"batch_\" + str(batch_size) + \",seed_\" + str(seed_size) + \",\" + str(heuristic) + \",X_hist\"\n",
        "            Y_hist_file_name = dir_name + \"batch_\" + str(batch_size) + \",seed_\" + str(seed_size) + \",\" + str(heuristic) + \",Y_hist\"\n",
        "\n",
        "            np.save(X_file_name, X_optimum) # results_IR/L2 is np array of shape (num_iterations + 1, seed_size)\n",
        "            np.save(Y_file_name, Y_optimum)\n",
        "            np.save(X_hist_file_name, bayes_opt.X)\n",
        "            np.save(Y_hist_file_name, bayes_opt.Y)\n",
        "\n",
        "            np.save(X_file_name, results_X_optimum)\n",
        "            np.save(Y_file_name, results_Y_optimum)\n",
        "            np.save(X_hist_file_name, results_X_hist)\n",
        "            np.save(Y_hist_file_name, results_Y_hist)\n",
        "\n",
        "    else: # Batch\n",
        "        num_batches = int(total_evals / batch_size)\n",
        "        results_X_hist = np.zeros(shape=(seed_size, total_evals + initial_num, input_dim))\n",
        "        results_X_optimum = np.zeros(shape=(seed_size, num_batches + 1, input_dim))\n",
        "        results_Y_hist = np.zeros(shape=(seed_size, total_evals + initial_num))\n",
        "        results_Y_optimum = np.zeros(shape=(seed_size, num_batches + 1))\n",
        "\n",
        "        for seed in range(seed_size):\n",
        "            print(\"Currently on seed: \", seed)\n",
        "            np.random.seed(seed)\n",
        "            set_random_seed(seed)\n",
        "\n",
        "            bayes_opt = Bayes_opt_batch(cifar_utils.cifar_cnn_fitbo, fitbo_lb, fitbo_ub, var_noise = 0, input_type = input_type)\n",
        "            bayes_opt.initialise(x_ob, y_ob)\n",
        "            X_optimum, Y_optimum = bayes_opt.iteration_step_batch(num_batches=num_batches, mc_burn=burnin, \\\n",
        "                                                                  mc_samples=sample_size, bo_method=BO_method, seed=seed, \\\n",
        "                                                                  resample_interval= resample_interval, batch_size = batch_size, \\\n",
        "                                                                  heuristic = heuristic, dir_name = dir_name)\n",
        "\n",
        "            results_X_hist[seed, :] = bayes_opt.X\n",
        "            results_X_optimum[seed, :] = X_optimum\n",
        "            results_Y_hist[seed, :] = bayes_opt.Y.flatten()\n",
        "            results_Y_optimum[seed, :] = Y_optimum.flatten()\n",
        "\n",
        "        X_file_name = dir_name + \"batch_\" + str(batch_size) + \",seed_\" + str(seed_size) + \",\" + str(heuristic) + \",X_optimum\"\n",
        "        Y_file_name = dir_name + \"batch_\" + str(batch_size) + \",seed_\" + str(seed_size) + \",\" + str(heuristic) + \",Y_optimum\"\n",
        "        X_hist_file_name = dir_name + \"batch_\" + str(batch_size) + \",seed_\" + str(seed_size) + \",\" + str(heuristic) + \",X_hist\"\n",
        "        Y_hist_file_name = dir_name + \"batch_\" + str(batch_size) + \",seed_\" + str(seed_size) + \",\" + str(heuristic) + \",Y_hist\"\n",
        "\n",
        "        np.save(X_file_name, results_X_optimum)\n",
        "        np.save(Y_file_name, results_Y_optimum)\n",
        "        np.save(X_hist_file_name, results_X_hist)\n",
        "        np.save(Y_hist_file_name, results_Y_hist)\n",
        "\n",
        "    return None\n",
        "\n",
        "batch_list = [2]\n",
        "heuristic_list = ['cl-min']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DWhi2DUPfput",
        "colab_type": "code",
        "outputId": "37b34222-ca0b-477b-8044-4b816d3ecf29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2234
        }
      },
      "cell_type": "code",
      "source": [
        "for batch in batch_list:\n",
        "    for heur in heuristic_list:\n",
        "        cifar_fitbo_wrapper(batch_size = batch, heuristic = heur)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Currently on seed:  0\n",
            "Not random, need reset GP\n",
            "Not random, need reset GP\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 63s 1ms/step - loss: 14.5103 - acc: 0.0997 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 63s 1ms/step - loss: 14.4976 - acc: 0.1005 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 63s 1ms/step - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 64s 1ms/step - loss: 14.4998 - acc: 0.1004 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 63s 1ms/step - loss: 14.4818 - acc: 0.1015 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 63s 1ms/step - loss: 14.5172 - acc: 0.0992 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 14.5402 - acc: 0.0979 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 14.5005 - acc: 0.1004 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 14.5319 - acc: 0.0984 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 63s 1ms/step - loss: 14.4900 - acc: 0.1010 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 18s 366us/step - loss: 1.5865 - acc: 0.4315 - val_loss: 1.3007 - val_acc: 0.5653\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 16s 324us/step - loss: 1.2865 - acc: 0.5551 - val_loss: 1.1633 - val_acc: 0.6052\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 16s 325us/step - loss: 1.2233 - acc: 0.5845 - val_loss: 1.0225 - val_acc: 0.6584\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 1.2183 - acc: 0.5896 - val_loss: 1.0288 - val_acc: 0.6599\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 1.2434 - acc: 0.5851 - val_loss: 1.2239 - val_acc: 0.5942\n",
            "bo:FITBOMM,seed:0,itr:0,x_next: [[ 4.         32.          0.67685153  0.09268515  0.45490509  0.1       ]],y_next:[[-0.1]\n",
            " [-0.1]], acq value: [0.49055496],x_opt:[1.6e+01 3.2e+01 2.0e-01 3.0e-01 2.0e-01 1.0e-03],y_opt:[-0.5942]\n",
            "Not random, need reset GP\n",
            "Not random, need reset GP\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 64s 1ms/step - loss: 14.4674 - acc: 0.1013 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 63s 1ms/step - loss: 14.5003 - acc: 0.0991 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 14.4765 - acc: 0.1009 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 14.4964 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 14.4997 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 62s 1ms/step - loss: 14.5303 - acc: 0.0984 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 62s 1ms/step - loss: 14.4947 - acc: 0.1007 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 61s 1ms/step - loss: 14.5114 - acc: 0.0997 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 62s 1ms/step - loss: 14.5053 - acc: 0.1001 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 61s 1ms/step - loss: 14.4921 - acc: 0.1009 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 19s 371us/step - loss: 1.6040 - acc: 0.4216 - val_loss: 1.2927 - val_acc: 0.5596\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 17s 343us/step - loss: 1.2956 - acc: 0.5509 - val_loss: 1.1551 - val_acc: 0.5991\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 17s 341us/step - loss: 1.2491 - acc: 0.5768 - val_loss: 1.0586 - val_acc: 0.6416\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 18s 369us/step - loss: 1.2529 - acc: 0.5811 - val_loss: 1.0752 - val_acc: 0.6385\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 19s 376us/step - loss: 1.2861 - acc: 0.5719 - val_loss: 1.1019 - val_acc: 0.6338\n",
            "bo:FITBOMM,seed:0,itr:1,x_next: [[ 4.         32.          1.          0.95857304  1.          0.09998911]],y_next:[[-0.1]\n",
            " [-0.1]], acq value: [0.49960551],x_opt:[1.6e+01 3.2e+01 2.0e-01 3.0e-01 2.0e-01 1.0e-03],y_opt:[-0.6338]\n",
            "Not random, need reset GP\n",
            "Not random, need reset GP\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 67s 1ms/step - loss: 14.0597 - acc: 0.1005 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 14.1412 - acc: 0.1014 - val_loss: 14.5095 - val_acc: 0.0998\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 64s 1ms/step - loss: 14.2560 - acc: 0.0980 - val_loss: 14.5095 - val_acc: 0.0998\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 14.2191 - acc: 0.1001 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 14.2064 - acc: 0.1002 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 67s 1ms/step - loss: 14.4294 - acc: 0.0991 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 14.4362 - acc: 0.0980 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 14.4294 - acc: 0.0984 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 14.4072 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 67s 1ms/step - loss: 14.4155 - acc: 0.0989 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 19s 380us/step - loss: 1.5977 - acc: 0.4227 - val_loss: 1.3267 - val_acc: 0.5411\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 19s 370us/step - loss: 1.3010 - acc: 0.5470 - val_loss: 1.1566 - val_acc: 0.6151\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 18s 361us/step - loss: 1.2343 - acc: 0.5800 - val_loss: 1.0096 - val_acc: 0.6601\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 17s 345us/step - loss: 1.2379 - acc: 0.5856 - val_loss: 0.9953 - val_acc: 0.6617\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 17s 346us/step - loss: 1.2749 - acc: 0.5760 - val_loss: 1.1053 - val_acc: 0.6317\n",
            "bo:FITBOMM,seed:0,itr:2,x_next: [[ 4.         32.          0.87413774  0.35712971  0.63964457  0.09999698]],y_next:[[-0.1]\n",
            " [-0.1]], acq value: [0.29181708],x_opt:[1.6e+01 3.2e+01 2.0e-01 3.0e-01 2.0e-01 1.0e-03],y_opt:[-0.6338]\n",
            "Not random, need reset GP\n",
            "Not random, need reset GP\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 62s 1ms/step - loss: 14.5058 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 62s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 58s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 64s 1ms/step - loss: 14.4874 - acc: 0.1011 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 61s 1ms/step - loss: 14.5073 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 62s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 61s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 19s 372us/step - loss: 1.5849 - acc: 0.4285 - val_loss: 1.2309 - val_acc: 0.5675\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 17s 335us/step - loss: 1.2793 - acc: 0.5586 - val_loss: 1.1525 - val_acc: 0.6079\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 18s 360us/step - loss: 1.2286 - acc: 0.5844 - val_loss: 1.2274 - val_acc: 0.5657\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 17s 333us/step - loss: 1.2380 - acc: 0.5876 - val_loss: 1.1498 - val_acc: 0.6100\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 17s 334us/step - loss: 1.2700 - acc: 0.5782 - val_loss: 1.3121 - val_acc: 0.5725\n",
            "bo:FITBOMM,seed:0,itr:3,x_next: [[ 4.         32.          1.          0.84360774  0.          0.09991604]],y_next:[[-0.1]\n",
            " [-0.1]], acq value: [0.51959869],x_opt:[1.6e+01 3.2e+01 2.0e-01 3.0e-01 2.0e-01 1.0e-03],y_opt:[-0.6338]\n",
            "Not random, need reset GP\n",
            "Not random, need reset GP\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 67s 1ms/step - loss: 14.5092 - acc: 0.0998 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 14.5098 - acc: 0.0998 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 14.5282 - acc: 0.0986 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 63s 1ms/step - loss: 14.5443 - acc: 0.0976 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 64s 1ms/step - loss: 14.5221 - acc: 0.0990 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 14.5049 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 2/5\n",
            " 3716/50000 [=>............................] - ETA: 52s - loss: 14.3267 - acc: 0.1111Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}